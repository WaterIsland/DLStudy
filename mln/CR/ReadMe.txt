・softmax関数を用いた Multi Layer Network を実装
	＊今回から、各層の活性化関数を個別に指定する方式に変更
		＋neuro_obj = mln.Mln().make_neuralnet([28*28, 100, 10], ['tanh', 'softmax'], 0.01, solved = 'classification')
		　の['tanh', 'softmax']で、中間層の活性化関数を'tanh'、出力層の活性化関数を'softmax'に設定している
	＊また、学習時における出力層の結合加重の更新式を適切に選択するため、解決する問題を指定する方式に変更
		＋neuro_obj = mln.Mln().make_neuralnet([28*28, 100, 10], ['tanh', 'softmax'], 0.01, solved = 'classification')
		　の'classification'で、クラス分類問題であることを設定している
		＋'fitting'が関数フィッティング、'classification'がクラス分類を意味するパラメータ

・mnist の手書き文字に対する学習／テストを実装
・学習は ./learn.py で実行
	＊入力層、中間層、出力層の３層で、ニューロン素子はそれぞれ784(28x28)、100、10個で、全結合
		＋neuro_obj = mln.Mln().make_neuralnet([28*28, 100, 10], ['tanh', 'softmax'], 0.01, solved = 'classification')
		　の[28*28, 100,10]の２番目のパラメータ'100'が中間層のニューロン素子の個数に該当
	＊bios は全ての層で一定値、学習対象外（近日実装予定）
	＊学習率：0.01
	＊活性化関数は、中間層は tanh
	＊訓練データ：mnistの学習用手書き画像60000個からランダムサンプリングして100000回（個）提示
		＋画素値を 0.0 - 1.0 で規格化した画像を利用
	＊教師データ：mnistの学習用手書き画像のラベルを提示
		＋ラベルを 1x10 の並列に変換して利用
	＊ネットワークの状態をダンプファイルで出力
		＋default-cr.dump：初期化直後のネットワークの状態をダンプしたファイル
		＋learn-cr.dump：学習後のネットワークの状態をダンプしたファイル

・テストは ./test.py で実行
	＊テストデータはmnistのt10k-images-idx3-ubyteを使用
	＊テストラベルはmnistのt10k-labels-idx1-ubyteを使用
	＊テストデータのラベルとニューラルネットが予測した結果を比較した結果を表示
		＋単純に、(誤認識数／データ総数)を表時

・自作の手書きデータによるテストは ./test-handwrite.py で実行
	＊opencv2 のプリインストールが必要
		＋macなら、 'brew install opencv' でインストールすること
	＊プログラム直下のファイル"image/number.png"を読み込んで、結果を以下のように表示
		judged: 9 , order array: [[9 3 2 7 5 8 4 0 6 1]]
	　数字の'9'だと認識し、[9 3 2 7 5 8 4 0 6 1]の順でその数字であると認識したことを意味している。
		＋数字の'9'である確率が最も高く、２番目に数字の'3'である確率が高く、３番目に数字の'2'である確率が高く、（以下略
	＊入力された画像のサイズは自動的に28x28に拡大・縮小されるので、正方形の形をした画像であれば問題ない（はず）

・学習後のニューラルネットワークは、以下のディレクトリに格納済み
	＊中間層のユニット数が異なるため、テスト結果に差有り
	＊中間層のユニット数が 1000個の場合は学習が不十分な可能性有り
	＊mnist-28x28-unit-100-epoch-100000/
		＋中間層のユニット数：100
		＋result.datに認識結果を出力済み、認識率：94.86%（誤差率：5.14%）

	＊mnist-28x28-unit-1000-epoch-100000/
		＋中間層のユニット数：1000
		＋result.datに認識結果を出力済み、認識率：93.26%（誤差率：6.74%）
		＋過適合と予想、確認手段は近日実装予定
