・softmax関数を用いた Multi Layer Network を実装
・mnist の手書き文字に対する学習／テストを実装
・学習は ./learn.py で実行
	＊入力層、中間層、出力層の３層で、ニューロン素子はそれぞれ784(28x28)、100、10個で、全結合
	＊bios は全ての層で一定値、学習対象外
	＊学習率：0.01
	＊活性化関数は、中間層は tanh
	＊訓練データ：mnistの手書き画像をランダムに10000個提示
		＋画素値を 0.0 - 1.0 で規格化した画像を利用
	＊教師データ：mnistの手書き画像のラベルを提示
		＋ラベルを 1x10 の並列に変換して利用
	＊ネットワークの状態をダンプファイルで出力
		＋default-cr.dump：初期化直後のネットワークの状態をダンプしたファイル
		＋learn-cr.dump：学習後のネットワークの状態をダンプしたファイル

・テストは ./test.py で実行
	＊テストデータはmnistのt10k-images-idx3-ubyteを使用
	＊テストラベルはmnistのt10k-labels-idx1-ubyteを使用
	＊テストデータのラベルとニューラルネットが予測した結果を比較した結果を表示
		＋単純に、(正解数／データ総数)を表時

・学習後のニューラルネットワークは、以下のディレクトリに格納済み
	＊中間層のユニット数が異なるため、テスト結果に差有り
	＊中間層のユニット数が 1000個の場合は学習が不十分な可能性有り
	＊mnist-28x28-unit-100-epoch-100000/
		＋中間層のユニット数：100

	＊mnist-28x28-unit-1000-epoch-100000/
		＋中間層のユニット数：1000

