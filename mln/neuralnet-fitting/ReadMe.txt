・学習に関するソースコードは、Micheal Nielsen のコードを参考に改良したもの
	＊http://nnadl-ja.github.io/nnadl_site_ja/index.html を参照
	＊訓練及びテストで利用するデータ構造も準拠
		＋ただし、多クラス分類のテストでは、データ構造は準拠していない
	＊オンライン学習、バッチ学習、ミニバッチ学習を実装
		＋ミニバッチ学習で、minibatch_size を訓練データ数に一致させればバッチ学習になる
			＠ミニバッチのアルゴリズムをそのまま利用するため、多クラス分類では非常に効率が悪いことに注意

・以下の機能を実装した Multi Layer Network
	＊関数フィッティング
		＋例題としてXORフィッティングを実装
		＋learn.py の fitting() を参照
		＋learn_batch.py の fitting() を参照
	＊２クラス分類
		＋例題としてXOR分類を実装
		＋learn.py の binary_classification() を参照
		＋learn_batch.py の binary_classification() を参照
	＊多クラス分類
		＋例題としてmnistの手書き文字認識を実装
		＋learn.py の classification() を参照
		＋learn_batch.py の classification() を参照

・オンライン学習の訓練（学習）は ./main.py で実行
・バッチ、ミニバッチ学習の訓練（学習）は ./main_batch.py で実行
	＊デフォルトで関数フィッティングが実行される
		＋他の機能を試したい場合はコメントアウトを外すこと

	$$$$$$$$$$$$$$$$$$$$$$$$$$$$
	[以下、オンライン学習の解説]
	$$$$$$$$$$$$$$$$$$$$$$$$$$$$

	＊関数フィッティングは、以下の構成

		nn_obj = mln.Mln().make_neuralnet([2, 3, 1], ['sigmoid', 'sigmoid'], eta = 0.15) # XOR fitting

		＋入力層、隠れ層、出力層の３層で、ニューロン・ノードはそれぞれ2、3、1個で全結合
		＋バイアス・ノードは入力層、隠れ層に１個ずつ設定し、結合加重の学習を実施
		＋隠れ層、出力層の活性化関数はシグモイド関数
		＋学習率は0.15
		＋ネットワークの状態をダンプファイルで出力
			＠学習済みのサンプルは、learn-pkl/online/fitting に格納
			＠default-fitting.pkl：初期化直後のネットワークの状態をダンプしたファイル
                	＠laern-fitting.pkl：学習後のネットワークの状態をダンプしたファイル

	＊２クラス分類は、以下の構成

		nn_obj = mln.Mln().make_neuralnet([2, 3, 1], ['sigmoid', 'sigmoid_binary'], eta = 0.15) # XOR classification

		＋入力層、隠れ層、出力層の３層で、ニューロン・ノードはそれぞれ2、3、1個で全結合
		＋バイアス・ノードは入力層、隠れ層に１個ずつ設定し、結合加重の学習を実施
		＋隠れ層、出力層の活性化関数はシグモイド関数
			＠ただし、出力層は２クラス分類用のシグモイド関数を指定していることに注意
				＄バックプロパゲーションで、関数フィッティングとは異なる偏微分結果になるため
		＋学習率は0.15
		＋ネットワークの状態をダンプファイルで出力
			＠学習済みのサンプルは、learn-pkl/online/binary-classification に格納
			＠default-binary-classification.pkl：初期化直後のネットワークの状態をダンプしたファイル
                	＠laern-binary-classification.pkl：学習後のネットワークの状態をダンプしたファイル

	＊多クラス分類は、以下の構成
		＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃
			学習率0.01バージョン
		＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃

		nn_obj = mln.Mln().make_neuralnet([28*28, 1000, num_class], ['sigmoid', 'softmax'], 0.01) # mnist classification

		＋入力層、隠れ層、出力層の３層で、ニューロン・ノードはそれぞれ28*28、1000、10個で全結合
		＋バイアス・ノードは入力層、隠れ層に１個ずつ設定し、結合加重の学習を実施
		＋隠れ層の活性化関数はシグモイド関数、出力層の活性化関数はソフトマックス関数
		＋学習率は0.01
		＋ネットワークの状態をダンプファイルで出力
			＠学習済みのサンプルは、learn-pkl/online/classification/eta-0.01-layer-784-1000-10/ に格納
			＠default-classification.pkl：初期化直後のネットワークの状態をダンプしたファイル
                	＠learn-classification.pkl：学習後のネットワークの状態をダンプしたファイル
			＠result.dat：テストデータを用いたテスト結果を出力したファイル
				＄認識ミスをした結果のみを出力
		＋訓練及びテストデータは ../../mnist/ に格納したデータを利用
			＠訓練データ：mnistの学習用手書き画像60000個からをランダムに100000個提示
			＠教師データ：mnistの学習用手書き画像のラベルを提示
				＄ラベルを 1x10 の並列に変換して利用
			＠テストデータ：mnistのテスト用手書き画像10000個全てを提示
			＠画素値を 0.0 - 1.0 で規格化した画像を利用

		＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃
			学習率0.15バージョン
		＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃

		nn_obj = mln.Mln().make_neuralnet([28*28, 1000, num_class], ['sigmoid', 'softmax'], 0.15) # mnist classification

		＋学習率は0.15
		＋ネットワークの状態をダンプファイルで出力
			＠学習済みのサンプルは、learn-pkl/classification/eta-0.15-layer-784-1000-10/ に格納
		＋その他設定は上記"学習率0.01バージョン"と同じ

	$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
	[以下、バッチ、ミニバッチ学習の解説]
		オンライン学習との相違点のみ記述
	$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

	＊関数フィッティングは、以下の構成
		＋ネットワークの状態をダンプファイルで出力
			＠学習済みのサンプルは、learn-pkl/minibatch/fitting に格納
                	＠laern-fitting-batch.pkl：学習後のネットワークの状態をダンプしたファイル

	＊２クラス分類は、以下の構成
		＋ネットワークの状態をダンプファイルで出力
			＠学習済みのサンプルは、learn-pkl/minibatch/binary-classification に格納
                	＠laern-binary-classification-batch.pkl：学習後のネットワークの状態をダンプしたファイル

	＊多クラス分類は、以下の構成
		＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃
			学習率0.01バージョン
		＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃

		＋ネットワークの状態をダンプファイルで出力
			＠学習済みのサンプルは、learn-pkl/minibatch/classification/minibatch-10x10000-eta-0.01-layer-784-1000-10/ に格納
				＄ 1バッチ10個を10000回訓練

		＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃
			学習率0.15バージョン
		＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃＃

		＋ネットワークの状態をダンプファイルで出力
			＠学習済みのサンプルは、learn-pkl/minibatch/classification/minibatch-10x10000-eta-0.15-layer-784-1000-10/ に格納
				＄ 1バッチ10個を10000回訓練
			＠学習済みのサンプルは、learn-pkl/minibatch/classification/minibatch-20x10000-eta-0.15-layer-784-1000-10/ に格納
				＄ 1バッチ20個を10000回訓練


・オンライン学習のテストは ./learn.py で実行
・バッチ、ミニバッチ学習のテストは ./learn_batch.py で実行
	＊現状は多クラス分類のみ実装
		＋その他情報は、上記訓練の多クラス分類の項目を参照
	＊その他問題は、./learn.py で実施するので実装していない

・自作手書きデータ認識
	＊test_handwrite.py を実行すると、../../hand-writing-number/ 内の以下のファイルの認識を実施
		＋0.png, 1.png, ..., 9.png
		＋number.png(デフォルトは数字の'9')
			＠gimp等のソフトで作成したpngを読み込める
		＋後述のバッチ、ミニバッチで試したい場合、読み込むpklファイルを変更すること
		＋読み込んでいる画像を表示する場合、recognition_digit_image() 末尾のコメントアウトを削除すること
			＠画像が表示されているウィンドウにフォーカスしている状態で、returnキーを押下するとウィンドウが閉じる
